{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710676c7",
   "metadata": {},
   "source": [
    "# Classification on BirdClef Dataset by using features from Whisper Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7219bcc",
   "metadata": {},
   "source": [
    "In this notebook, we performed classification on BirdClef Dataset. The feature is extracted using Whisper encoder, which are then passed to different variation of CNN model to determine the species class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a45740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import whisper\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cac8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc0fe0",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ae91e",
   "metadata": {},
   "source": [
    "This notebook has 4 variations that it can run on, which are given as:\n",
    "1. augmentedRun = True  + FTRun = True      : If you want to run the model on augmented dataset by fine tuning the model\n",
    "2. augmentedRun = False + FTRun = True      : If you want to run the model on raw dataset by fine tuning the model\n",
    "3. augmentedRun = True  + FTRun = False     : If you want to run the model on augmented dataset by not fine tuning the model\n",
    "4. augmentedRun = False + FTRun = False     : If you want to run the model on raw dataset without fine tuning\n",
    "\n",
    "needToMakePT = False : For model to run, we are passing mel spectrogram to the whisper encoder instead of audios. If you need to first convert the audios to mel spectrogram, pass True to the flag so on first run, it'll convert all audios to mel spectrogram and save it to torch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550207e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to run model for augmented dataset or raw dataset\n",
    "augmentedRun = True\n",
    "FTRun = True\n",
    "randomWeight = False\n",
    "\n",
    "# Prepare PT (Required 1st time only & you need to have original ogg audios)\n",
    "# added this code so we can save time over the epoch by saving mel\n",
    "needToMakePT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44e851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting directory paths as per the configuration\n",
    "if(augmentedRun):\n",
    "    csvPath = \"./dataset/pt_files/augmented.csv\"\n",
    "    audio_folder_path = './dataset/audio_files/augmented_audio/' # not required to set if pt files are already there\n",
    "    main_folder_path = \"./dataset/pt_files/augmented/\"\n",
    "else:\n",
    "    csvPath = \"./dataset/pt_files/original.csv\"\n",
    "    audio_folder_path = './dataset/audio_files/original/' # not required to set if pt files are already there\n",
    "    main_folder_path = \"./dataset/pt_files/original/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfee390",
   "metadata": {},
   "source": [
    "Set paths for the checkpoints and create folders if they don't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f319927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for checkpoints\n",
    "base_checkpoint_path = './checkpoints'\n",
    "\n",
    "# Determine the folder names based on the flag states\n",
    "config_name = f\"{'dAugmented_' if augmentedRun else 'dOriginal'}\" \\\n",
    "              f\"{'mFineTuned_' if FTRun else 'mFrozen_'}\" \\\n",
    "              f\"{'wRandom' if randomWeight else 'wPretrained'}\"\n",
    "\n",
    "# Construct the full paths for train and test checkpoints\n",
    "train_checkpoint_path = os.path.join(base_checkpoint_path, config_name, 'train')\n",
    "test_checkpoint_path = os.path.join(base_checkpoint_path, config_name, 'test')\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(train_checkpoint_path, exist_ok=True)\n",
    "os.makedirs(test_checkpoint_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef86c86",
   "metadata": {},
   "source": [
    "## Loading Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e30776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_Name</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>colsun2/XC122411.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>colsun2/XC736024.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>colsun2/XC516528.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>colsun2/XC650873.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>colsun2/XC323386.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label_Name          filename_pt\n",
       "0    colsun2  colsun2/XC122411.pt\n",
       "1    colsun2  colsun2/XC736024.pt\n",
       "2    colsun2  colsun2/XC516528.pt\n",
       "3    colsun2  colsun2/XC650873.pt\n",
       "4    colsun2  colsun2/XC323386.pt"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the file from the path as per the config\n",
    "df = pd.read_csv(csvPath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bac595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28748, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c69b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28748 entries, 0 to 28747\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Label_Name   28748 non-null  object\n",
      " 1   filename_pt  28748 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 449.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c326e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_Name</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28748</td>\n",
       "      <td>28748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>217</td>\n",
       "      <td>28748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>barswa</td>\n",
       "      <td>colsun2/XC122411.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label_Name          filename_pt\n",
       "count       28748                28748\n",
       "unique        217                28748\n",
       "top        barswa  colsun2/XC122411.pt\n",
       "freq          500                    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bd453",
   "metadata": {},
   "source": [
    "## Thresholding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81513546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28748\n",
      "{'colsun2': 181, 'carcha1': 153, 'norfis1': 84, 'meypar1': 142, 'huncis1': 63, 'loceag1': 69, 'malkin1': 57, 'marsun2': 174, 'eswdov1': 75, 'crohor1': 233, 'sincis1': 79, 'rewsta1': 117, 'slbgre1': 95, 'helgui': 75, 'whbtit5': 88, 'brcale1': 43, 'kerspa2': 151, 'beasun2': 155, 'litegr': 378, 'brobab1': 103, 'gabgos2': 176, 'hamerk1': 114, 'vilwea1': 106, 'wtbeat1': 112, 'cibwar1': 113, 'afrgrp1': 99, 'afrthr1': 251, 'refbar2': 46, 'spepig1': 162, 'nubwoo1': 86, 'reboxp1': 87, 'lawgol': 92, 'klacuc1': 66, 'litswi1': 99, 'moccha1': 197, 'gycwar3': 66, 'yelbis1': 77, 'yenspu1': 47, 'gyhspa1': 214, 'libeat1': 108, 'rindov': 116, 'yertin1': 134, 'gryapa1': 115, 'blcapa2': 92, 'broman1': 156, 'sltnig1': 151, 'afpwag1': 97, 'gyhkin1': 61, 'afghor1': 87, 'gnhsun1': 83, 'bkctch1': 109, 'mabeat1': 68, 'grccra1': 58, 'ruegls1': 166, 'rbsrob1': 281, 'wookin1': 79, 'gargan': 136, 'ratcis1': 172, 'brctch1': 74, 'grbcam1': 114, 'blakit1': 262, 'wbgbir1': 112, 'hartur1': 73, 'blwlap1': 57, 'refcro1': 174, 'scthon1': 115, 'scrcha1': 133, 'gyhbus1': 92, 'whbwea1': 76, 'yebduc1': 65, 'yebapa1': 106, 'yespet1': 60, 'yetgre1': 102, 'chtapa3': 117, 'luebus1': 80, 'sobfly1': 87, 'bltori1': 84, 'grewoo2': 103, 'supsta1': 153, 'pygbat1': 59, 'varsun2': 105, 'norcro1': 103, 'slcbou1': 65, 'yebbar1': 156, 'grecor': 138, 'norbro1': 87, 'vimwea1': 80, 'spfwea1': 47, 'spfbar1': 53, 'squher1': 165, 'bawhor2': 205, 'wheslf1': 70, 'wbswea1': 97, 'darbar1': 138, 'tamdov1': 121, 'pitwhy': 65, 'grywrw1': 85, 'eaywag1': 500, 'gnbcam2': 239, 'yesbar1': 131, 'yewgre1': 108, 'tafpri1': 161, 'gybfis1': 47, 'blhher1': 64, 'trobou1': 116, 'piekin1': 121, 'afecuc1': 109, 'gbesta1': 204, 'abethr1': 62, 'whbcan1': 42, 'litwea1': 71, 'amesun2': 189, 'eubeat1': 437, 'purgre2': 35, 'blksaw1': 46, 'barswa': 500, 'reccuc1': 122, 'spwlap1': 71, 'brosun1': 125, 'gobbun1': 101, 'abythr1': 128, 'comsan': 500, 'yebgre1': 98, 'cohmar1': 425, 'spmthr1': 111, 'spewea1': 117, 'raybar1': 67, 'fotdro5': 137, 'laudov1': 109, 'lesmaw1': 66, 'blnmou1': 117, 'subbus1': 108, 'btweye2': 82, 'strsee1': 140, 'wfbeat1': 183, 'rostur1': 39, 'lessts1': 157, 'bltapa1': 46, 'whihel1': 59, 'combul2': 293, 'bagwea1': 94, 'wlwwar': 500, 'afdfly1': 127, 'edcsun3': 85, 'hoopoe': 436, 'yebere1': 152, 'combuz1': 477, 'rebhor1': 130, 'whbcou1': 89, 'chibat1': 94, 'brican1': 122, 'mouwag1': 136, 'reccor': 67, 'afrgos1': 70, 'augbuz1': 43, 'walsta1': 162, 'soufis1': 201, 'blbpuf2': 166, 'palfly2': 56, 'spemou2': 163, 'butapa1': 132, 'yeccan1': 55, 'hadibi1': 129, 'somtit4': 88, 'piecro1': 109, 'quailf1': 172, 'crheag1': 151, 'fislov1': 57, 'ccbeat1': 57, 'affeag1': 170, 'rebfir2': 203, 'egygoo': 152, 'reisee2': 104, 'yefcan': 94, 'brwwar1': 173, 'blaplo1': 200, 'blfbus1': 175, 'nobfly1': 85, 'rocmar2': 100, 'blhgon1': 99, 'cabgre1': 141, 'easmog1': 60, 'greegr': 252, 'strher': 119, 'didcuc1': 94, 'bcbeat1': 96, 'rerswa1': 227, 'bkfruw1': 120, 'blacuc1': 97, 'somgre1': 199, 'abhori1': 126, 'afpfly1': 104, 'thrnig1': 500, 'reftin1': 71, 'brubru1': 99, 'categr': 166, 'woosan': 486, 'sichor1': 197, 'soucit1': 92, 'fatrav1': 99, 'blnwea1': 68, 'reedov1': 85, 'blacra1': 75, 'gyhneg1': 91, 'wbrcha2': 132, 'sccsun2': 94, 'grwpyt1': 105, 'ndcsun2': 103, 'bswdov1': 124, 'afrjac1': 114, 'vibsta2': 81, 'carwoo1': 199, 'afmdov1': 176, 'chucis1': 112, 'norpuf1': 88, 'whbwhe3': 144, 'afbfly1': 82}\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "\n",
    "bird_dist_dict = {}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    total_count = total_count + 1\n",
    "    # print(df.loc[i, \"primary_label\"])\n",
    "    temp_label = df.loc[i, \"Label_Name\"]\n",
    "    if temp_label in bird_dist_dict:\n",
    "      bird_dist_dict[temp_label] = bird_dist_dict[temp_label] + 1\n",
    "    else:\n",
    "      bird_dist_dict[temp_label] = 1\n",
    "\n",
    "\n",
    "print(total_count)\n",
    "print(bird_dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b37b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['colsun2', 'carcha1', 'norfis1', 'meypar1', 'huncis1', 'loceag1', 'malkin1', 'marsun2', 'eswdov1', 'crohor1', 'sincis1', 'rewsta1', 'slbgre1', 'helgui', 'whbtit5', 'brcale1', 'kerspa2', 'beasun2', 'litegr', 'brobab1', 'gabgos2', 'hamerk1', 'vilwea1', 'wtbeat1', 'cibwar1', 'afrgrp1', 'afrthr1', 'refbar2', 'spepig1', 'nubwoo1', 'reboxp1', 'lawgol', 'klacuc1', 'litswi1', 'moccha1', 'gycwar3', 'yelbis1', 'yenspu1', 'gyhspa1', 'libeat1', 'rindov', 'yertin1', 'gryapa1', 'blcapa2', 'broman1', 'sltnig1', 'afpwag1', 'gyhkin1', 'afghor1', 'gnhsun1', 'bkctch1', 'mabeat1', 'grccra1', 'ruegls1', 'rbsrob1', 'wookin1', 'gargan', 'ratcis1', 'brctch1', 'grbcam1', 'blakit1', 'wbgbir1', 'hartur1', 'blwlap1', 'refcro1', 'scthon1', 'scrcha1', 'gyhbus1', 'whbwea1', 'yebduc1', 'yebapa1', 'yespet1', 'yetgre1', 'chtapa3', 'luebus1', 'sobfly1', 'bltori1', 'grewoo2', 'supsta1', 'pygbat1', 'varsun2', 'norcro1', 'slcbou1', 'yebbar1', 'grecor', 'norbro1', 'vimwea1', 'spfwea1', 'spfbar1', 'squher1', 'bawhor2', 'wheslf1', 'wbswea1', 'darbar1', 'tamdov1', 'pitwhy', 'grywrw1', 'eaywag1', 'gnbcam2', 'yesbar1', 'yewgre1', 'tafpri1', 'gybfis1', 'blhher1', 'trobou1', 'piekin1', 'afecuc1', 'gbesta1', 'abethr1', 'whbcan1', 'litwea1', 'amesun2', 'eubeat1', 'purgre2', 'blksaw1', 'barswa', 'reccuc1', 'spwlap1', 'brosun1', 'gobbun1', 'abythr1', 'comsan', 'yebgre1', 'cohmar1', 'spmthr1', 'spewea1', 'raybar1', 'fotdro5', 'laudov1', 'lesmaw1', 'blnmou1', 'subbus1', 'btweye2', 'strsee1', 'wfbeat1', 'rostur1', 'lessts1', 'bltapa1', 'whihel1', 'combul2', 'bagwea1', 'wlwwar', 'afdfly1', 'edcsun3', 'hoopoe', 'yebere1', 'combuz1', 'rebhor1', 'whbcou1', 'chibat1', 'brican1', 'mouwag1', 'reccor', 'afrgos1', 'augbuz1', 'walsta1', 'soufis1', 'blbpuf2', 'palfly2', 'spemou2', 'butapa1', 'yeccan1', 'hadibi1', 'somtit4', 'piecro1', 'quailf1', 'crheag1', 'fislov1', 'ccbeat1', 'affeag1', 'rebfir2', 'egygoo', 'reisee2', 'yefcan', 'brwwar1', 'blaplo1', 'blfbus1', 'nobfly1', 'rocmar2', 'blhgon1', 'cabgre1', 'easmog1', 'greegr', 'strher', 'didcuc1', 'bcbeat1', 'rerswa1', 'bkfruw1', 'blacuc1', 'somgre1', 'abhori1', 'afpfly1', 'thrnig1', 'reftin1', 'brubru1', 'categr', 'woosan', 'sichor1', 'soucit1', 'fatrav1', 'blnwea1', 'reedov1', 'blacra1', 'gyhneg1', 'wbrcha2', 'sccsun2', 'grwpyt1', 'ndcsun2', 'bswdov1', 'afrjac1', 'vibsta2', 'carwoo1', 'afmdov1', 'chucis1', 'norpuf1', 'whbwhe3', 'afbfly1'])\n",
      "dict_values([181, 153, 84, 142, 63, 69, 57, 174, 75, 233, 79, 117, 95, 75, 88, 43, 151, 155, 378, 103, 176, 114, 106, 112, 113, 99, 251, 46, 162, 86, 87, 92, 66, 99, 197, 66, 77, 47, 214, 108, 116, 134, 115, 92, 156, 151, 97, 61, 87, 83, 109, 68, 58, 166, 281, 79, 136, 172, 74, 114, 262, 112, 73, 57, 174, 115, 133, 92, 76, 65, 106, 60, 102, 117, 80, 87, 84, 103, 153, 59, 105, 103, 65, 156, 138, 87, 80, 47, 53, 165, 205, 70, 97, 138, 121, 65, 85, 500, 239, 131, 108, 161, 47, 64, 116, 121, 109, 204, 62, 42, 71, 189, 437, 35, 46, 500, 122, 71, 125, 101, 128, 500, 98, 425, 111, 117, 67, 137, 109, 66, 117, 108, 82, 140, 183, 39, 157, 46, 59, 293, 94, 500, 127, 85, 436, 152, 477, 130, 89, 94, 122, 136, 67, 70, 43, 162, 201, 166, 56, 163, 132, 55, 129, 88, 109, 172, 151, 57, 57, 170, 203, 152, 104, 94, 173, 200, 175, 85, 100, 99, 141, 60, 252, 119, 94, 96, 227, 120, 97, 199, 126, 104, 500, 71, 99, 166, 486, 197, 92, 99, 68, 85, 75, 91, 132, 94, 105, 103, 124, 114, 81, 199, 176, 112, 88, 144, 82])\n",
      "217\n",
      "28748\n",
      "['colsun2', 'carcha1', 'norfis1', 'meypar1', 'huncis1', 'loceag1', 'malkin1', 'marsun2', 'eswdov1', 'crohor1', 'sincis1', 'rewsta1', 'slbgre1', 'helgui', 'whbtit5', 'brcale1', 'kerspa2', 'beasun2', 'litegr', 'brobab1', 'gabgos2', 'hamerk1', 'vilwea1', 'wtbeat1', 'cibwar1', 'afrgrp1', 'afrthr1', 'refbar2', 'spepig1', 'nubwoo1', 'reboxp1', 'lawgol', 'klacuc1', 'litswi1', 'moccha1', 'gycwar3', 'yelbis1', 'yenspu1', 'gyhspa1', 'libeat1', 'rindov', 'yertin1', 'gryapa1', 'blcapa2', 'broman1', 'sltnig1', 'afpwag1', 'gyhkin1', 'afghor1', 'gnhsun1', 'bkctch1', 'mabeat1', 'grccra1', 'ruegls1', 'rbsrob1', 'wookin1', 'gargan', 'ratcis1', 'brctch1', 'grbcam1', 'blakit1', 'wbgbir1', 'hartur1', 'blwlap1', 'refcro1', 'scthon1', 'scrcha1', 'gyhbus1', 'whbwea1', 'yebduc1', 'yebapa1', 'yespet1', 'yetgre1', 'chtapa3', 'luebus1', 'sobfly1', 'bltori1', 'grewoo2', 'supsta1', 'pygbat1', 'varsun2', 'norcro1', 'slcbou1', 'yebbar1', 'grecor', 'norbro1', 'vimwea1', 'spfwea1', 'spfbar1', 'squher1', 'bawhor2', 'wheslf1', 'wbswea1', 'darbar1', 'tamdov1', 'pitwhy', 'grywrw1', 'eaywag1', 'gnbcam2', 'yesbar1', 'yewgre1', 'tafpri1', 'gybfis1', 'blhher1', 'trobou1', 'piekin1', 'afecuc1', 'gbesta1', 'abethr1', 'whbcan1', 'litwea1', 'amesun2', 'eubeat1', 'purgre2', 'blksaw1', 'barswa', 'reccuc1', 'spwlap1', 'brosun1', 'gobbun1', 'abythr1', 'comsan', 'yebgre1', 'cohmar1', 'spmthr1', 'spewea1', 'raybar1', 'fotdro5', 'laudov1', 'lesmaw1', 'blnmou1', 'subbus1', 'btweye2', 'strsee1', 'wfbeat1', 'rostur1', 'lessts1', 'bltapa1', 'whihel1', 'combul2', 'bagwea1', 'wlwwar', 'afdfly1', 'edcsun3', 'hoopoe', 'yebere1', 'combuz1', 'rebhor1', 'whbcou1', 'chibat1', 'brican1', 'mouwag1', 'reccor', 'afrgos1', 'augbuz1', 'walsta1', 'soufis1', 'blbpuf2', 'palfly2', 'spemou2', 'butapa1', 'yeccan1', 'hadibi1', 'somtit4', 'piecro1', 'quailf1', 'crheag1', 'fislov1', 'ccbeat1', 'affeag1', 'rebfir2', 'egygoo', 'reisee2', 'yefcan', 'brwwar1', 'blaplo1', 'blfbus1', 'nobfly1', 'rocmar2', 'blhgon1', 'cabgre1', 'easmog1', 'greegr', 'strher', 'didcuc1', 'bcbeat1', 'rerswa1', 'bkfruw1', 'blacuc1', 'somgre1', 'abhori1', 'afpfly1', 'thrnig1', 'reftin1', 'brubru1', 'categr', 'woosan', 'sichor1', 'soucit1', 'fatrav1', 'blnwea1', 'reedov1', 'blacra1', 'gyhneg1', 'wbrcha2', 'sccsun2', 'grwpyt1', 'ndcsun2', 'bswdov1', 'afrjac1', 'vibsta2', 'carwoo1', 'afmdov1', 'chucis1', 'norpuf1', 'whbwhe3', 'afbfly1']\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "names = bird_dist_dict.keys()\n",
    "values = bird_dist_dict.values()\n",
    "\n",
    "print(names)\n",
    "print(values)\n",
    "print(len(names))\n",
    "\n",
    "values = list(values)\n",
    "print(np.sum(values))\n",
    "names = list(names)\n",
    "print(names)\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdf0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 0\n",
    "threshold = 1\n",
    "\n",
    "selected_species_list = []\n",
    "\n",
    "for i in range(len(values)):\n",
    "    if values[i] < threshold:\n",
    "        min_count += 1\n",
    "\n",
    "    else:\n",
    "        selected_species_list.append(names[i])\n",
    "\n",
    "print(min_count)\n",
    "len(selected_species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d39c886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28748"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "  temp_label = df.loc[i, \"Label_Name\"]\n",
    "  if temp_label in selected_species_list:\n",
    "      pass\n",
    "  else:\n",
    "    df=df.drop(df.index[total_count])\n",
    "    total_count = total_count - 1\n",
    "\n",
    "  total_count = total_count + 1\n",
    "total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7afdec2",
   "metadata": {},
   "source": [
    "## Convert Primary Labels (strings) to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e032dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Elements in 'primary_labels' List = 28748\n",
      "No. of Elements in 'primary_labels_unique' List = 217\n"
     ]
    }
   ],
   "source": [
    "primary_labels = df['Label_Name'].values.tolist()\n",
    "\n",
    "\n",
    "print(f\"No. of Elements in 'primary_labels' List = {len(primary_labels)}\")\n",
    "\n",
    "primary_labels_unique = sorted(list(set(primary_labels)))  \n",
    "\n",
    "print(f\"No. of Elements in 'primary_labels_unique' List = {len(primary_labels_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd9f874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abethr1',\n",
       " 'abhori1',\n",
       " 'abythr1',\n",
       " 'afbfly1',\n",
       " 'afdfly1',\n",
       " 'afecuc1',\n",
       " 'affeag1',\n",
       " 'afghor1',\n",
       " 'afmdov1',\n",
       " 'afpfly1',\n",
       " 'afpwag1',\n",
       " 'afrgos1',\n",
       " 'afrgrp1',\n",
       " 'afrjac1',\n",
       " 'afrthr1',\n",
       " 'amesun2',\n",
       " 'augbuz1',\n",
       " 'bagwea1',\n",
       " 'barswa',\n",
       " 'bawhor2',\n",
       " 'bcbeat1',\n",
       " 'beasun2',\n",
       " 'bkctch1',\n",
       " 'bkfruw1',\n",
       " 'blacra1',\n",
       " 'blacuc1',\n",
       " 'blakit1',\n",
       " 'blaplo1',\n",
       " 'blbpuf2',\n",
       " 'blcapa2',\n",
       " 'blfbus1',\n",
       " 'blhgon1',\n",
       " 'blhher1',\n",
       " 'blksaw1',\n",
       " 'blnmou1',\n",
       " 'blnwea1',\n",
       " 'bltapa1',\n",
       " 'bltori1',\n",
       " 'blwlap1',\n",
       " 'brcale1',\n",
       " 'brctch1',\n",
       " 'brican1',\n",
       " 'brobab1',\n",
       " 'broman1',\n",
       " 'brosun1',\n",
       " 'brubru1',\n",
       " 'brwwar1',\n",
       " 'bswdov1',\n",
       " 'btweye2',\n",
       " 'butapa1',\n",
       " 'cabgre1',\n",
       " 'carcha1',\n",
       " 'carwoo1',\n",
       " 'categr',\n",
       " 'ccbeat1',\n",
       " 'chibat1',\n",
       " 'chtapa3',\n",
       " 'chucis1',\n",
       " 'cibwar1',\n",
       " 'cohmar1',\n",
       " 'colsun2',\n",
       " 'combul2',\n",
       " 'combuz1',\n",
       " 'comsan',\n",
       " 'crheag1',\n",
       " 'crohor1',\n",
       " 'darbar1',\n",
       " 'didcuc1',\n",
       " 'easmog1',\n",
       " 'eaywag1',\n",
       " 'edcsun3',\n",
       " 'egygoo',\n",
       " 'eswdov1',\n",
       " 'eubeat1',\n",
       " 'fatrav1',\n",
       " 'fislov1',\n",
       " 'fotdro5',\n",
       " 'gabgos2',\n",
       " 'gargan',\n",
       " 'gbesta1',\n",
       " 'gnbcam2',\n",
       " 'gnhsun1',\n",
       " 'gobbun1',\n",
       " 'grbcam1',\n",
       " 'grccra1',\n",
       " 'grecor',\n",
       " 'greegr',\n",
       " 'grewoo2',\n",
       " 'grwpyt1',\n",
       " 'gryapa1',\n",
       " 'grywrw1',\n",
       " 'gybfis1',\n",
       " 'gycwar3',\n",
       " 'gyhbus1',\n",
       " 'gyhkin1',\n",
       " 'gyhneg1',\n",
       " 'gyhspa1',\n",
       " 'hadibi1',\n",
       " 'hamerk1',\n",
       " 'hartur1',\n",
       " 'helgui',\n",
       " 'hoopoe',\n",
       " 'huncis1',\n",
       " 'kerspa2',\n",
       " 'klacuc1',\n",
       " 'laudov1',\n",
       " 'lawgol',\n",
       " 'lesmaw1',\n",
       " 'lessts1',\n",
       " 'libeat1',\n",
       " 'litegr',\n",
       " 'litswi1',\n",
       " 'litwea1',\n",
       " 'loceag1',\n",
       " 'luebus1',\n",
       " 'mabeat1',\n",
       " 'malkin1',\n",
       " 'marsun2',\n",
       " 'meypar1',\n",
       " 'moccha1',\n",
       " 'mouwag1',\n",
       " 'ndcsun2',\n",
       " 'nobfly1',\n",
       " 'norbro1',\n",
       " 'norcro1',\n",
       " 'norfis1',\n",
       " 'norpuf1',\n",
       " 'nubwoo1',\n",
       " 'palfly2',\n",
       " 'piecro1',\n",
       " 'piekin1',\n",
       " 'pitwhy',\n",
       " 'purgre2',\n",
       " 'pygbat1',\n",
       " 'quailf1',\n",
       " 'ratcis1',\n",
       " 'raybar1',\n",
       " 'rbsrob1',\n",
       " 'rebfir2',\n",
       " 'rebhor1',\n",
       " 'reboxp1',\n",
       " 'reccor',\n",
       " 'reccuc1',\n",
       " 'reedov1',\n",
       " 'refbar2',\n",
       " 'refcro1',\n",
       " 'reftin1',\n",
       " 'reisee2',\n",
       " 'rerswa1',\n",
       " 'rewsta1',\n",
       " 'rindov',\n",
       " 'rocmar2',\n",
       " 'rostur1',\n",
       " 'ruegls1',\n",
       " 'sccsun2',\n",
       " 'scrcha1',\n",
       " 'scthon1',\n",
       " 'sichor1',\n",
       " 'sincis1',\n",
       " 'slbgre1',\n",
       " 'slcbou1',\n",
       " 'sltnig1',\n",
       " 'sobfly1',\n",
       " 'somgre1',\n",
       " 'somtit4',\n",
       " 'soucit1',\n",
       " 'soufis1',\n",
       " 'spemou2',\n",
       " 'spepig1',\n",
       " 'spewea1',\n",
       " 'spfbar1',\n",
       " 'spfwea1',\n",
       " 'spmthr1',\n",
       " 'spwlap1',\n",
       " 'squher1',\n",
       " 'strher',\n",
       " 'strsee1',\n",
       " 'subbus1',\n",
       " 'supsta1',\n",
       " 'tafpri1',\n",
       " 'tamdov1',\n",
       " 'thrnig1',\n",
       " 'trobou1',\n",
       " 'varsun2',\n",
       " 'vibsta2',\n",
       " 'vilwea1',\n",
       " 'vimwea1',\n",
       " 'walsta1',\n",
       " 'wbgbir1',\n",
       " 'wbrcha2',\n",
       " 'wbswea1',\n",
       " 'wfbeat1',\n",
       " 'whbcan1',\n",
       " 'whbcou1',\n",
       " 'whbtit5',\n",
       " 'whbwea1',\n",
       " 'whbwhe3',\n",
       " 'wheslf1',\n",
       " 'whihel1',\n",
       " 'wlwwar',\n",
       " 'wookin1',\n",
       " 'woosan',\n",
       " 'wtbeat1',\n",
       " 'yebapa1',\n",
       " 'yebbar1',\n",
       " 'yebduc1',\n",
       " 'yebere1',\n",
       " 'yebgre1',\n",
       " 'yeccan1',\n",
       " 'yefcan',\n",
       " 'yelbis1',\n",
       " 'yenspu1',\n",
       " 'yertin1',\n",
       " 'yesbar1',\n",
       " 'yespet1',\n",
       " 'yetgre1',\n",
       " 'yewgre1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_labels_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10dd7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird2label_dict = {}   # this dictionary will give integer 'label' when a 'bird' name is used in key\n",
    "label2bird_dict = {}   # this dictionary will give 'bird' name when integer 'label' is used in key\n",
    "\n",
    "\n",
    "for i, bird in enumerate(primary_labels_unique):\n",
    "    bird2label_dict[bird] = i\n",
    "    label2bird_dict[i] = bird\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e42aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abethr1': 0,\n",
       " 'abhori1': 1,\n",
       " 'abythr1': 2,\n",
       " 'afbfly1': 3,\n",
       " 'afdfly1': 4,\n",
       " 'afecuc1': 5,\n",
       " 'affeag1': 6,\n",
       " 'afghor1': 7,\n",
       " 'afmdov1': 8,\n",
       " 'afpfly1': 9,\n",
       " 'afpwag1': 10,\n",
       " 'afrgos1': 11,\n",
       " 'afrgrp1': 12,\n",
       " 'afrjac1': 13,\n",
       " 'afrthr1': 14,\n",
       " 'amesun2': 15,\n",
       " 'augbuz1': 16,\n",
       " 'bagwea1': 17,\n",
       " 'barswa': 18,\n",
       " 'bawhor2': 19,\n",
       " 'bcbeat1': 20,\n",
       " 'beasun2': 21,\n",
       " 'bkctch1': 22,\n",
       " 'bkfruw1': 23,\n",
       " 'blacra1': 24,\n",
       " 'blacuc1': 25,\n",
       " 'blakit1': 26,\n",
       " 'blaplo1': 27,\n",
       " 'blbpuf2': 28,\n",
       " 'blcapa2': 29,\n",
       " 'blfbus1': 30,\n",
       " 'blhgon1': 31,\n",
       " 'blhher1': 32,\n",
       " 'blksaw1': 33,\n",
       " 'blnmou1': 34,\n",
       " 'blnwea1': 35,\n",
       " 'bltapa1': 36,\n",
       " 'bltori1': 37,\n",
       " 'blwlap1': 38,\n",
       " 'brcale1': 39,\n",
       " 'brctch1': 40,\n",
       " 'brican1': 41,\n",
       " 'brobab1': 42,\n",
       " 'broman1': 43,\n",
       " 'brosun1': 44,\n",
       " 'brubru1': 45,\n",
       " 'brwwar1': 46,\n",
       " 'bswdov1': 47,\n",
       " 'btweye2': 48,\n",
       " 'butapa1': 49,\n",
       " 'cabgre1': 50,\n",
       " 'carcha1': 51,\n",
       " 'carwoo1': 52,\n",
       " 'categr': 53,\n",
       " 'ccbeat1': 54,\n",
       " 'chibat1': 55,\n",
       " 'chtapa3': 56,\n",
       " 'chucis1': 57,\n",
       " 'cibwar1': 58,\n",
       " 'cohmar1': 59,\n",
       " 'colsun2': 60,\n",
       " 'combul2': 61,\n",
       " 'combuz1': 62,\n",
       " 'comsan': 63,\n",
       " 'crheag1': 64,\n",
       " 'crohor1': 65,\n",
       " 'darbar1': 66,\n",
       " 'didcuc1': 67,\n",
       " 'easmog1': 68,\n",
       " 'eaywag1': 69,\n",
       " 'edcsun3': 70,\n",
       " 'egygoo': 71,\n",
       " 'eswdov1': 72,\n",
       " 'eubeat1': 73,\n",
       " 'fatrav1': 74,\n",
       " 'fislov1': 75,\n",
       " 'fotdro5': 76,\n",
       " 'gabgos2': 77,\n",
       " 'gargan': 78,\n",
       " 'gbesta1': 79,\n",
       " 'gnbcam2': 80,\n",
       " 'gnhsun1': 81,\n",
       " 'gobbun1': 82,\n",
       " 'grbcam1': 83,\n",
       " 'grccra1': 84,\n",
       " 'grecor': 85,\n",
       " 'greegr': 86,\n",
       " 'grewoo2': 87,\n",
       " 'grwpyt1': 88,\n",
       " 'gryapa1': 89,\n",
       " 'grywrw1': 90,\n",
       " 'gybfis1': 91,\n",
       " 'gycwar3': 92,\n",
       " 'gyhbus1': 93,\n",
       " 'gyhkin1': 94,\n",
       " 'gyhneg1': 95,\n",
       " 'gyhspa1': 96,\n",
       " 'hadibi1': 97,\n",
       " 'hamerk1': 98,\n",
       " 'hartur1': 99,\n",
       " 'helgui': 100,\n",
       " 'hoopoe': 101,\n",
       " 'huncis1': 102,\n",
       " 'kerspa2': 103,\n",
       " 'klacuc1': 104,\n",
       " 'laudov1': 105,\n",
       " 'lawgol': 106,\n",
       " 'lesmaw1': 107,\n",
       " 'lessts1': 108,\n",
       " 'libeat1': 109,\n",
       " 'litegr': 110,\n",
       " 'litswi1': 111,\n",
       " 'litwea1': 112,\n",
       " 'loceag1': 113,\n",
       " 'luebus1': 114,\n",
       " 'mabeat1': 115,\n",
       " 'malkin1': 116,\n",
       " 'marsun2': 117,\n",
       " 'meypar1': 118,\n",
       " 'moccha1': 119,\n",
       " 'mouwag1': 120,\n",
       " 'ndcsun2': 121,\n",
       " 'nobfly1': 122,\n",
       " 'norbro1': 123,\n",
       " 'norcro1': 124,\n",
       " 'norfis1': 125,\n",
       " 'norpuf1': 126,\n",
       " 'nubwoo1': 127,\n",
       " 'palfly2': 128,\n",
       " 'piecro1': 129,\n",
       " 'piekin1': 130,\n",
       " 'pitwhy': 131,\n",
       " 'purgre2': 132,\n",
       " 'pygbat1': 133,\n",
       " 'quailf1': 134,\n",
       " 'ratcis1': 135,\n",
       " 'raybar1': 136,\n",
       " 'rbsrob1': 137,\n",
       " 'rebfir2': 138,\n",
       " 'rebhor1': 139,\n",
       " 'reboxp1': 140,\n",
       " 'reccor': 141,\n",
       " 'reccuc1': 142,\n",
       " 'reedov1': 143,\n",
       " 'refbar2': 144,\n",
       " 'refcro1': 145,\n",
       " 'reftin1': 146,\n",
       " 'reisee2': 147,\n",
       " 'rerswa1': 148,\n",
       " 'rewsta1': 149,\n",
       " 'rindov': 150,\n",
       " 'rocmar2': 151,\n",
       " 'rostur1': 152,\n",
       " 'ruegls1': 153,\n",
       " 'sccsun2': 154,\n",
       " 'scrcha1': 155,\n",
       " 'scthon1': 156,\n",
       " 'sichor1': 157,\n",
       " 'sincis1': 158,\n",
       " 'slbgre1': 159,\n",
       " 'slcbou1': 160,\n",
       " 'sltnig1': 161,\n",
       " 'sobfly1': 162,\n",
       " 'somgre1': 163,\n",
       " 'somtit4': 164,\n",
       " 'soucit1': 165,\n",
       " 'soufis1': 166,\n",
       " 'spemou2': 167,\n",
       " 'spepig1': 168,\n",
       " 'spewea1': 169,\n",
       " 'spfbar1': 170,\n",
       " 'spfwea1': 171,\n",
       " 'spmthr1': 172,\n",
       " 'spwlap1': 173,\n",
       " 'squher1': 174,\n",
       " 'strher': 175,\n",
       " 'strsee1': 176,\n",
       " 'subbus1': 177,\n",
       " 'supsta1': 178,\n",
       " 'tafpri1': 179,\n",
       " 'tamdov1': 180,\n",
       " 'thrnig1': 181,\n",
       " 'trobou1': 182,\n",
       " 'varsun2': 183,\n",
       " 'vibsta2': 184,\n",
       " 'vilwea1': 185,\n",
       " 'vimwea1': 186,\n",
       " 'walsta1': 187,\n",
       " 'wbgbir1': 188,\n",
       " 'wbrcha2': 189,\n",
       " 'wbswea1': 190,\n",
       " 'wfbeat1': 191,\n",
       " 'whbcan1': 192,\n",
       " 'whbcou1': 193,\n",
       " 'whbtit5': 194,\n",
       " 'whbwea1': 195,\n",
       " 'whbwhe3': 196,\n",
       " 'wheslf1': 197,\n",
       " 'whihel1': 198,\n",
       " 'wlwwar': 199,\n",
       " 'wookin1': 200,\n",
       " 'woosan': 201,\n",
       " 'wtbeat1': 202,\n",
       " 'yebapa1': 203,\n",
       " 'yebbar1': 204,\n",
       " 'yebduc1': 205,\n",
       " 'yebere1': 206,\n",
       " 'yebgre1': 207,\n",
       " 'yeccan1': 208,\n",
       " 'yefcan': 209,\n",
       " 'yelbis1': 210,\n",
       " 'yenspu1': 211,\n",
       " 'yertin1': 212,\n",
       " 'yesbar1': 213,\n",
       " 'yespet1': 214,\n",
       " 'yetgre1': 215,\n",
       " 'yewgre1': 216}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird2label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6382563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'abethr1',\n",
       " 1: 'abhori1',\n",
       " 2: 'abythr1',\n",
       " 3: 'afbfly1',\n",
       " 4: 'afdfly1',\n",
       " 5: 'afecuc1',\n",
       " 6: 'affeag1',\n",
       " 7: 'afghor1',\n",
       " 8: 'afmdov1',\n",
       " 9: 'afpfly1',\n",
       " 10: 'afpwag1',\n",
       " 11: 'afrgos1',\n",
       " 12: 'afrgrp1',\n",
       " 13: 'afrjac1',\n",
       " 14: 'afrthr1',\n",
       " 15: 'amesun2',\n",
       " 16: 'augbuz1',\n",
       " 17: 'bagwea1',\n",
       " 18: 'barswa',\n",
       " 19: 'bawhor2',\n",
       " 20: 'bcbeat1',\n",
       " 21: 'beasun2',\n",
       " 22: 'bkctch1',\n",
       " 23: 'bkfruw1',\n",
       " 24: 'blacra1',\n",
       " 25: 'blacuc1',\n",
       " 26: 'blakit1',\n",
       " 27: 'blaplo1',\n",
       " 28: 'blbpuf2',\n",
       " 29: 'blcapa2',\n",
       " 30: 'blfbus1',\n",
       " 31: 'blhgon1',\n",
       " 32: 'blhher1',\n",
       " 33: 'blksaw1',\n",
       " 34: 'blnmou1',\n",
       " 35: 'blnwea1',\n",
       " 36: 'bltapa1',\n",
       " 37: 'bltori1',\n",
       " 38: 'blwlap1',\n",
       " 39: 'brcale1',\n",
       " 40: 'brctch1',\n",
       " 41: 'brican1',\n",
       " 42: 'brobab1',\n",
       " 43: 'broman1',\n",
       " 44: 'brosun1',\n",
       " 45: 'brubru1',\n",
       " 46: 'brwwar1',\n",
       " 47: 'bswdov1',\n",
       " 48: 'btweye2',\n",
       " 49: 'butapa1',\n",
       " 50: 'cabgre1',\n",
       " 51: 'carcha1',\n",
       " 52: 'carwoo1',\n",
       " 53: 'categr',\n",
       " 54: 'ccbeat1',\n",
       " 55: 'chibat1',\n",
       " 56: 'chtapa3',\n",
       " 57: 'chucis1',\n",
       " 58: 'cibwar1',\n",
       " 59: 'cohmar1',\n",
       " 60: 'colsun2',\n",
       " 61: 'combul2',\n",
       " 62: 'combuz1',\n",
       " 63: 'comsan',\n",
       " 64: 'crheag1',\n",
       " 65: 'crohor1',\n",
       " 66: 'darbar1',\n",
       " 67: 'didcuc1',\n",
       " 68: 'easmog1',\n",
       " 69: 'eaywag1',\n",
       " 70: 'edcsun3',\n",
       " 71: 'egygoo',\n",
       " 72: 'eswdov1',\n",
       " 73: 'eubeat1',\n",
       " 74: 'fatrav1',\n",
       " 75: 'fislov1',\n",
       " 76: 'fotdro5',\n",
       " 77: 'gabgos2',\n",
       " 78: 'gargan',\n",
       " 79: 'gbesta1',\n",
       " 80: 'gnbcam2',\n",
       " 81: 'gnhsun1',\n",
       " 82: 'gobbun1',\n",
       " 83: 'grbcam1',\n",
       " 84: 'grccra1',\n",
       " 85: 'grecor',\n",
       " 86: 'greegr',\n",
       " 87: 'grewoo2',\n",
       " 88: 'grwpyt1',\n",
       " 89: 'gryapa1',\n",
       " 90: 'grywrw1',\n",
       " 91: 'gybfis1',\n",
       " 92: 'gycwar3',\n",
       " 93: 'gyhbus1',\n",
       " 94: 'gyhkin1',\n",
       " 95: 'gyhneg1',\n",
       " 96: 'gyhspa1',\n",
       " 97: 'hadibi1',\n",
       " 98: 'hamerk1',\n",
       " 99: 'hartur1',\n",
       " 100: 'helgui',\n",
       " 101: 'hoopoe',\n",
       " 102: 'huncis1',\n",
       " 103: 'kerspa2',\n",
       " 104: 'klacuc1',\n",
       " 105: 'laudov1',\n",
       " 106: 'lawgol',\n",
       " 107: 'lesmaw1',\n",
       " 108: 'lessts1',\n",
       " 109: 'libeat1',\n",
       " 110: 'litegr',\n",
       " 111: 'litswi1',\n",
       " 112: 'litwea1',\n",
       " 113: 'loceag1',\n",
       " 114: 'luebus1',\n",
       " 115: 'mabeat1',\n",
       " 116: 'malkin1',\n",
       " 117: 'marsun2',\n",
       " 118: 'meypar1',\n",
       " 119: 'moccha1',\n",
       " 120: 'mouwag1',\n",
       " 121: 'ndcsun2',\n",
       " 122: 'nobfly1',\n",
       " 123: 'norbro1',\n",
       " 124: 'norcro1',\n",
       " 125: 'norfis1',\n",
       " 126: 'norpuf1',\n",
       " 127: 'nubwoo1',\n",
       " 128: 'palfly2',\n",
       " 129: 'piecro1',\n",
       " 130: 'piekin1',\n",
       " 131: 'pitwhy',\n",
       " 132: 'purgre2',\n",
       " 133: 'pygbat1',\n",
       " 134: 'quailf1',\n",
       " 135: 'ratcis1',\n",
       " 136: 'raybar1',\n",
       " 137: 'rbsrob1',\n",
       " 138: 'rebfir2',\n",
       " 139: 'rebhor1',\n",
       " 140: 'reboxp1',\n",
       " 141: 'reccor',\n",
       " 142: 'reccuc1',\n",
       " 143: 'reedov1',\n",
       " 144: 'refbar2',\n",
       " 145: 'refcro1',\n",
       " 146: 'reftin1',\n",
       " 147: 'reisee2',\n",
       " 148: 'rerswa1',\n",
       " 149: 'rewsta1',\n",
       " 150: 'rindov',\n",
       " 151: 'rocmar2',\n",
       " 152: 'rostur1',\n",
       " 153: 'ruegls1',\n",
       " 154: 'sccsun2',\n",
       " 155: 'scrcha1',\n",
       " 156: 'scthon1',\n",
       " 157: 'sichor1',\n",
       " 158: 'sincis1',\n",
       " 159: 'slbgre1',\n",
       " 160: 'slcbou1',\n",
       " 161: 'sltnig1',\n",
       " 162: 'sobfly1',\n",
       " 163: 'somgre1',\n",
       " 164: 'somtit4',\n",
       " 165: 'soucit1',\n",
       " 166: 'soufis1',\n",
       " 167: 'spemou2',\n",
       " 168: 'spepig1',\n",
       " 169: 'spewea1',\n",
       " 170: 'spfbar1',\n",
       " 171: 'spfwea1',\n",
       " 172: 'spmthr1',\n",
       " 173: 'spwlap1',\n",
       " 174: 'squher1',\n",
       " 175: 'strher',\n",
       " 176: 'strsee1',\n",
       " 177: 'subbus1',\n",
       " 178: 'supsta1',\n",
       " 179: 'tafpri1',\n",
       " 180: 'tamdov1',\n",
       " 181: 'thrnig1',\n",
       " 182: 'trobou1',\n",
       " 183: 'varsun2',\n",
       " 184: 'vibsta2',\n",
       " 185: 'vilwea1',\n",
       " 186: 'vimwea1',\n",
       " 187: 'walsta1',\n",
       " 188: 'wbgbir1',\n",
       " 189: 'wbrcha2',\n",
       " 190: 'wbswea1',\n",
       " 191: 'wfbeat1',\n",
       " 192: 'whbcan1',\n",
       " 193: 'whbcou1',\n",
       " 194: 'whbtit5',\n",
       " 195: 'whbwea1',\n",
       " 196: 'whbwhe3',\n",
       " 197: 'wheslf1',\n",
       " 198: 'whihel1',\n",
       " 199: 'wlwwar',\n",
       " 200: 'wookin1',\n",
       " 201: 'woosan',\n",
       " 202: 'wtbeat1',\n",
       " 203: 'yebapa1',\n",
       " 204: 'yebbar1',\n",
       " 205: 'yebduc1',\n",
       " 206: 'yebere1',\n",
       " 207: 'yebgre1',\n",
       " 208: 'yeccan1',\n",
       " 209: 'yefcan',\n",
       " 210: 'yelbis1',\n",
       " 211: 'yenspu1',\n",
       " 212: 'yertin1',\n",
       " 213: 'yesbar1',\n",
       " 214: 'yespet1',\n",
       " 215: 'yetgre1',\n",
       " 216: 'yewgre1'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2bird_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0fff97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a lambda function to 'primary_labels' column\n",
    "lambda_function = lambda bird : bird2label_dict[bird]    \n",
    "\n",
    "df.insert(1, 'labels', None) # adding new column 'labels' at index=1. all values will be None in this column\n",
    "\n",
    "df['labels'] = df['Label_Name'].apply(lambda_function)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75c874a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_Name</th>\n",
       "      <th>labels</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC122411.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC736024.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC516528.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC650873.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colsun2</td>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC323386.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label_Name  labels          filename_pt\n",
       "0    colsun2      60  colsun2/XC122411.pt\n",
       "1    colsun2      60  colsun2/XC736024.pt\n",
       "2    colsun2      60  colsun2/XC516528.pt\n",
       "3    colsun2      60  colsun2/XC650873.pt\n",
       "4    colsun2      60  colsun2/XC323386.pt"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e80671",
   "metadata": {},
   "source": [
    "Converting Audios to Mel Spectrogram, if needToMakePT flag is set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "988b7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF NEED TO DO MEL SAVING HERE\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_audio_to_mel_pt(audio_folder_path, pt_folder_path):\n",
    "    # Create Path objects for folder paths\n",
    "    audio_folder = Path(audio_folder_path)\n",
    "    pt_folder = Path(pt_folder_path)\n",
    "\n",
    "    # Iterate over each label folder\n",
    "    for label_folder in audio_folder.iterdir():\n",
    "        if label_folder.is_dir():\n",
    "            label = label_folder.name\n",
    "\n",
    "            # Count .ogg files and proceed only if there are at least 10\n",
    "            ogg_files = list(label_folder.glob('*.ogg'))\n",
    "            # Create corresponding label folder in pt_folder_path\n",
    "            label_pt_folder = pt_folder / label\n",
    "            label_pt_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Process each .ogg file\n",
    "            for ogg_file in ogg_files:\n",
    "                ogg_file_path = str(ogg_file)\n",
    "                pt_file_name = ogg_file.stem + '.pt'  # Change extension to .pt\n",
    "                pt_file_path = label_pt_folder / pt_file_name\n",
    "\n",
    "                # Check if .pt file already exists\n",
    "                if not pt_file_path.exists():\n",
    "                    # Load and process audio file\n",
    "                    audio_waveform = whisper.load_audio(ogg_file_path)\n",
    "                    audio_waveform = torch.from_numpy(whisper.pad_or_trim(audio_waveform))\n",
    "                    mel = whisper.log_mel_spectrogram(audio_waveform)\n",
    "\n",
    "                    # Save the mel spectrogram, moving it back to CPU\n",
    "                    torch.save(mel, pt_file_path)\n",
    "\n",
    "\n",
    "if needToMakePT:\n",
    "    convert_audio_to_mel_pt(audio_folder_path, main_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df210d",
   "metadata": {},
   "source": [
    "The dataframe is finalized after removing the extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1add472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_filename(row):\n",
    "#     filename = row['Augment_Filename'] if pd.notna(row['Augment_Filename']) else \\\n",
    "#                (row['Segment_Filename'] if pd.notna(row['Segment_Filename']) else row['OG_Filename'])\n",
    "#     return f\"{row['Label_Name']}/{filename}\"\n",
    "\n",
    "# df['filename'] = df.apply(create_filename, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70107c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_labels_paths = df[['labels', 'filename_pt']]\n",
    "\n",
    "# # apply a lambda function to 'primary_labels' column\n",
    "# lambda_function_pt = lambda ogg_filename : ogg_filename.split('.')[0] + '.pt'  \n",
    "\n",
    "# df_labels_paths.insert(2, 'filename_pt', None) # adding new column 'labels' at index=1. all values will be None in this column\n",
    "\n",
    "# df_labels_paths['filename_pt'] = df_labels_paths['filename'].apply(lambda_function_pt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d3aebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC122411.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC736024.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC516528.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC650873.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>colsun2/XC323386.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels          filename_pt\n",
       "0      60  colsun2/XC122411.pt\n",
       "1      60  colsun2/XC736024.pt\n",
       "2      60  colsun2/XC516528.pt\n",
       "3      60  colsun2/XC650873.pt\n",
       "4      60  colsun2/XC323386.pt"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e6c9c",
   "metadata": {},
   "source": [
    "## Train-Test Split of BirdClef Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab67211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# using stratify for unbalanced classes of dataset by keeping the random state fixed\n",
    "\n",
    "\n",
    "classes_with_few_instances = df_labels_paths['labels'].value_counts()[df_labels_paths['labels'].value_counts() < 3].index\n",
    "\n",
    "# Separate data into two parts: one with classes having >= 3 instances and one with the rest\n",
    "df_with_few_instances = df_labels_paths[df_labels_paths['labels'].isin(classes_with_few_instances)]\n",
    "df_remaining_instances = df_labels_paths[~df_labels_paths['labels'].isin(classes_with_few_instances)]\n",
    "\n",
    "# Perform stratified split on the remaining instances\n",
    "df_train_remaining, df_test_remaining = train_test_split(\n",
    "    df_remaining_instances, \n",
    "    test_size=0.2, \n",
    "    stratify=df_remaining_instances[['labels']], \n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Include one instance from each class in both training and testing sets\n",
    "df_train = pd.concat([df_train_remaining, df_with_few_instances.groupby('labels').head(1)])\n",
    "df_test = pd.concat([df_test_remaining, df_with_few_instances.groupby('labels').tail(1)])\n",
    "\n",
    "# Shuffle the resulting DataFrames\n",
    "df_train = df_train.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d68cc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>somtit4/XC531235_chunk0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>grecor/XC344284.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>gnbcam2/XC611575.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>lessts1/lessts1_gaussiannoise_XC362145.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>combuz1/XC180279.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22993</th>\n",
       "      <td>147</td>\n",
       "      <td>reisee2/XC444370_chunk30.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22994</th>\n",
       "      <td>53</td>\n",
       "      <td>categr/XC45476.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22995</th>\n",
       "      <td>156</td>\n",
       "      <td>scthon1/XC266088_chunk0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22996</th>\n",
       "      <td>26</td>\n",
       "      <td>blakit1/XC640160.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22997</th>\n",
       "      <td>127</td>\n",
       "      <td>nubwoo1/nubwoo1_gaussiannoise_XC281995.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                filename_pt\n",
       "0         164                 somtit4/XC531235_chunk0.pt\n",
       "1          85                         grecor/XC344284.pt\n",
       "2          80                        gnbcam2/XC611575.pt\n",
       "3         108  lessts1/lessts1_gaussiannoise_XC362145.pt\n",
       "4          62                        combuz1/XC180279.pt\n",
       "...       ...                                        ...\n",
       "22993     147                reisee2/XC444370_chunk30.pt\n",
       "22994      53                          categr/XC45476.pt\n",
       "22995     156                 scthon1/XC266088_chunk0.pt\n",
       "22996      26                        blakit1/XC640160.pt\n",
       "22997     127  nubwoo1/nubwoo1_gaussiannoise_XC281995.pt\n",
       "\n",
       "[22998 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed2aca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>cohmar1/XC432610.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>afdfly1/afdfly1_gain_XC247896.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>comsan/XC746247.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>afrgrp1/XC656721_chunk0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>spfbar1/XC755404.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>134</td>\n",
       "      <td>quailf1/XC364312.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>86</td>\n",
       "      <td>greegr/XC554102.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>154</td>\n",
       "      <td>sccsun2/XC195527.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>71</td>\n",
       "      <td>egygoo/XC656474.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5749</th>\n",
       "      <td>13</td>\n",
       "      <td>afrjac1/afrjac1_gaussiannoise_XC477662.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                filename_pt\n",
       "0         59                        cohmar1/XC432610.pt\n",
       "1          4           afdfly1/afdfly1_gain_XC247896.pt\n",
       "2         63                         comsan/XC746247.pt\n",
       "3         12                 afrgrp1/XC656721_chunk0.pt\n",
       "4        170                        spfbar1/XC755404.pt\n",
       "...      ...                                        ...\n",
       "5745     134                        quailf1/XC364312.pt\n",
       "5746      86                         greegr/XC554102.pt\n",
       "5747     154                        sccsun2/XC195527.pt\n",
       "5748      71                         egygoo/XC656474.pt\n",
       "5749      13  afrjac1/afrjac1_gaussiannoise_XC477662.pt\n",
       "\n",
       "[5750 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b96fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Samples in Train Split = 22998\n",
      "No. of Samples in Test Split  = 5750\n",
      "No. of Classes in Train Split  = 217\n",
      "No. of Samples in Test Split  = 217\n"
     ]
    }
   ],
   "source": [
    "print(f'No. of Samples in Train Split = {df_train.shape[0]}')\n",
    "print(f'No. of Samples in Test Split  = {df_test.shape[0]}')\n",
    "print(f'No. of Classes in Train Split  = {df_train[\"labels\"].nunique()}')\n",
    "print(f'No. of Samples in Test Split  = {df_test[\"labels\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9084f4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC514893.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC633745.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gaussiannoise_XC400373.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC367462.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC633977.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC633970.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515341.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC115988.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC125108.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515340_chunk0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC667105.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC634001.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC633982.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gaussiannoise_XC515239.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                filename_pt\n",
       "58        11                        afrgos1/XC514893.pt\n",
       "160       11                        afrgos1/XC633745.pt\n",
       "739       11  afrgos1/afrgos1_gaussiannoise_XC400373.pt\n",
       "849       11                        afrgos1/XC367462.pt\n",
       "1094      11                        afrgos1/XC633977.pt\n",
       "2003      11                        afrgos1/XC633970.pt\n",
       "2390      11                        afrgos1/XC515341.pt\n",
       "3404      11                        afrgos1/XC115988.pt\n",
       "3909      11                        afrgos1/XC125108.pt\n",
       "4083      11                 afrgos1/XC515340_chunk0.pt\n",
       "4147      11                        afrgos1/XC667105.pt\n",
       "4319      11                        afrgos1/XC634001.pt\n",
       "4663      11                        afrgos1/XC633982.pt\n",
       "5312      11  afrgos1/afrgos1_gaussiannoise_XC515239.pt"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['labels'] == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f5362a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>filename_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC336458.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC123946.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC267463_chunk30.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC418707.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515237.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC115984.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515667.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC660394.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gaussiannoise_XC515667.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC745559.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC634016.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC147873.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC652454.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gain_XC177121.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC514892.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7947</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC470600.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC682153.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC633968.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC522590.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC755402.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10520</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC115990.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10530</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515236.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10760</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC690375.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10856</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC289502.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC516786.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC350903.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12374</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC718285.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12381</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gain_XC115984.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12582</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC400373.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC516545.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC516514.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gaussiannoise_XC634001.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13211</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC267463.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13622</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC690375_chunk0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14706</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC440295.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC442057.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15570</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC690375_chunk30.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16375</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC634015.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16819</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC664994.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17599</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515241.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17711</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC177121.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17782</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC317870.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17794</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC517330.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17857</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC265441.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18432</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gain_XC516545.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18441</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515340.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC440296.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19346</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC712458.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC516698.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20770</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/afrgos1_gaussiannoise_XC667105.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20832</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC115986.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21510</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515239.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21591</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC755400.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21677</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC267463_chunk0.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22465</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC515238.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22467</th>\n",
       "      <td>11</td>\n",
       "      <td>afrgos1/XC374358.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                filename_pt\n",
       "487        11                        afrgos1/XC336458.pt\n",
       "832        11                        afrgos1/XC123946.pt\n",
       "1657       11                afrgos1/XC267463_chunk30.pt\n",
       "1759       11                        afrgos1/XC418707.pt\n",
       "1896       11                        afrgos1/XC515237.pt\n",
       "2295       11                        afrgos1/XC115984.pt\n",
       "2383       11                        afrgos1/XC515667.pt\n",
       "3459       11                        afrgos1/XC660394.pt\n",
       "3489       11  afrgos1/afrgos1_gaussiannoise_XC515667.pt\n",
       "4462       11                        afrgos1/XC745559.pt\n",
       "4497       11                        afrgos1/XC634016.pt\n",
       "4577       11                        afrgos1/XC147873.pt\n",
       "4783       11                        afrgos1/XC652454.pt\n",
       "5225       11           afrgos1/afrgos1_gain_XC177121.pt\n",
       "5417       11                        afrgos1/XC514892.pt\n",
       "7947       11                        afrgos1/XC470600.pt\n",
       "8474       11                        afrgos1/XC682153.pt\n",
       "9318       11                        afrgos1/XC633968.pt\n",
       "10000      11                        afrgos1/XC522590.pt\n",
       "10164      11                        afrgos1/XC755402.pt\n",
       "10520      11                        afrgos1/XC115990.pt\n",
       "10530      11                        afrgos1/XC515236.pt\n",
       "10760      11                        afrgos1/XC690375.pt\n",
       "10856      11                        afrgos1/XC289502.pt\n",
       "11805      11                        afrgos1/XC516786.pt\n",
       "12000      11                        afrgos1/XC350903.pt\n",
       "12374      11                        afrgos1/XC718285.pt\n",
       "12381      11           afrgos1/afrgos1_gain_XC115984.pt\n",
       "12582      11                        afrgos1/XC400373.pt\n",
       "12609      11                        afrgos1/XC516545.pt\n",
       "12806      11                        afrgos1/XC516514.pt\n",
       "12820      11  afrgos1/afrgos1_gaussiannoise_XC634001.pt\n",
       "13211      11                        afrgos1/XC267463.pt\n",
       "13622      11                 afrgos1/XC690375_chunk0.pt\n",
       "14706      11                        afrgos1/XC440295.pt\n",
       "14998      11                        afrgos1/XC442057.pt\n",
       "15570      11                afrgos1/XC690375_chunk30.pt\n",
       "16375      11                        afrgos1/XC634015.pt\n",
       "16819      11                        afrgos1/XC664994.pt\n",
       "17599      11                        afrgos1/XC515241.pt\n",
       "17711      11                        afrgos1/XC177121.pt\n",
       "17782      11                        afrgos1/XC317870.pt\n",
       "17794      11                        afrgos1/XC517330.pt\n",
       "17857      11                        afrgos1/XC265441.pt\n",
       "18432      11           afrgos1/afrgos1_gain_XC516545.pt\n",
       "18441      11                        afrgos1/XC515340.pt\n",
       "18707      11                        afrgos1/XC440296.pt\n",
       "19346      11                        afrgos1/XC712458.pt\n",
       "19996      11                        afrgos1/XC516698.pt\n",
       "20770      11  afrgos1/afrgos1_gaussiannoise_XC667105.pt\n",
       "20832      11                        afrgos1/XC115986.pt\n",
       "21510      11                        afrgos1/XC515239.pt\n",
       "21591      11                        afrgos1/XC755400.pt\n",
       "21677      11                 afrgos1/XC267463_chunk0.pt\n",
       "22465      11                        afrgos1/XC515238.pt\n",
       "22467      11                        afrgos1/XC374358.pt"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['labels'] == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67764e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Sub-folders in Main-Folder = 217\n"
     ]
    }
   ],
   "source": [
    "sub_folders_list = os.listdir(main_folder_path)\n",
    "print(f\"No. of Sub-folders in Main-Folder = {len(sub_folders_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e162ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files_path_train = df_train['filename_pt'].values.tolist()\n",
    "#extracts the values in the \"filename\" column of the DataFrame and converts them into a Python list\n",
    "\n",
    "labels_train = df_train['labels'].values.tolist()\n",
    "#extracts the values in the \"primary_label_encoded\" column of the DataFrame and converts them into a Python list. \n",
    "\n",
    "audio_files_path_test = df_test['filename_pt'].values.tolist()\n",
    "#print(audio_files_path_test)\n",
    "labels_test = df_test['labels'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a0e84",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "A custom dataset class, in the context of machine learning and deep learning frameworks like PyTorch or TensorFlow, is a user-defined class that extends or implements the functionality of a framework-specific dataset class. It is used to encapsulate and organize your custom data in a format that can be easily consumed by machine learning models during training, validation, or testing.\n",
    "\n",
    "**Initialization (__init__):**  \n",
    "The constructor define how the dataset should be initialized. This include loading data from files, preparing labels, and setting up any necessary transformations or preprocessing steps.\n",
    "\n",
    "**Length (__len__):**  \n",
    "Implemented a method to return the total number of data samples in the dataset.\n",
    "\n",
    "**Indexing (__getitem__):**  \n",
    "This method defines how an individual data sample is retrieved based on its index. It loads the data and their corresponding labels, applies any necessary transformations, and returns them as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "400afc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3c326a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdClefDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, audio_files_path, labels, main_folder_path, bird2label_dict=None, label2bird_dict=None):\n",
    "\n",
    "        \n",
    "        self.audio_files_path = audio_files_path\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.main_folder_path = main_folder_path\n",
    "        \n",
    "        self.bird2label_dict = bird2label_dict\n",
    "        self.label2bird_dict = label2bird_dict\n",
    "        \n",
    "    \n",
    "    # this function is used by 'Dataset' class to check the total number of samples in dataset\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get path of audio file indicated by index\n",
    "        # self.audio_files_path is a list which contains paths of audio files. each element in this list corresponds to the path of an audio file.\n",
    "        audio_path = self.audio_files_path[index]  # audio_path contains the address of audio which is specified in index\n",
    "\n",
    "    \n",
    "    \n",
    "        # get full path of the mel file\n",
    "        # audio_full_path is a variable that stores the complete file path to the audio file we want to load.\n",
    "        audio_full_path = os.path.join(self.main_folder_path, audio_path)\n",
    "\n",
    "        mel = torch.load(audio_full_path)\n",
    "        \n",
    "        label = torch.tensor(self.labels[index]) \n",
    "         \n",
    "        return mel, label, self.label2bird_dict[label.item()]\n",
    "        # return mel, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a961e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BirdClefDataset(audio_files_path_train, labels_train, main_folder_path, bird2label_dict=bird2label_dict, label2bird_dict=label2bird_dict)\n",
    "\n",
    "test_dataset = BirdClefDataset(audio_files_path_test, labels_test, main_folder_path , bird2label_dict=bird2label_dict, label2bird_dict=label2bird_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6854a71",
   "metadata": {},
   "source": [
    "# DataLoaders\n",
    "A DataLoader is a utility class provided by the torch.utils.data module that helps you load and manage data for training and evaluation of machine learning models, particularly deep learning models. It is commonly used in combination with the Dataset class to create a seamless pipeline for feeding data into your model during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0215d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "shuffle = True \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5278f030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train_dataset =  22998\n",
      "Length of the test_dataset  =  5750\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the train_dataset = \", len(train_dataset))\n",
    "print(\"Length of the test_dataset  = \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a114806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 1438\n",
      "Number of Batches: 360\n"
     ]
    }
   ],
   "source": [
    "num_batches = len(train_dataloader)\n",
    "print(\"Number of Batches:\", num_batches)\n",
    "\n",
    "num_batches = len(test_dataloader)\n",
    "print(\"Number of Batches:\", num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "179a7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d85f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eb86b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216]\n"
     ]
    }
   ],
   "source": [
    "labels_unique = sorted(list(set(df['labels'])))  \n",
    "print(labels_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489d513",
   "metadata": {},
   "source": [
    "**Run-time Augmentation**\n",
    "\n",
    "These functions are used to perform run time augmentation during the augmentedRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9773a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_masking(mel_spec):\n",
    "    starting_point = random.sample(range(3000), 1)\n",
    "    width = random.sample(range(300, 500), 1)\n",
    "    temp_mel = mel_spec.clone()\n",
    "    temp_mel[:, starting_point[0] : starting_point[0] + width[0]] = -1\n",
    "\n",
    "    # tensor_to_img(temp_mel.numpy())\n",
    "    return temp_mel\n",
    "\n",
    "def freq_masking(mel_spec):\n",
    "    starting_point = random.sample(range(1, 80), 1)\n",
    "    width = random.sample(range(12, 16), 1)\n",
    "    temp_mel = mel_spec.clone()\n",
    "    temp_mel[starting_point[0] : starting_point[0] + width[0], :] = -1\n",
    "\n",
    "    # tensor_to_img(temp_mel.numpy())\n",
    "    return temp_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662cfe7",
   "metadata": {},
   "source": [
    "**Defining CNN model here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ead1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 372 * 125, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 217)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 372 * 125)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e4ad7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save log\n",
    "def add_log(text):\n",
    "    try:\n",
    "        # Try to open the file in append mode\n",
    "        with open(config_name + \".txt\", 'a') as file:\n",
    "            file.write(text)  # Append the string and add a newline\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it and write the string\n",
    "        with open(config_name + \".txt\", 'w') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2dbfd",
   "metadata": {},
   "source": [
    "## Deep Learning Model Training and Testing Loops\n",
    "\n",
    "train_loop and test_loop, designed for training and evaluating a deep learning model. It integrates the Whisper model for feature extraction and includes both data augmentation and classification report generation. The training loop applies frequency and time masking for data augmentation, while both loops calculate loss, accuracy, F1 score, and save model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a89b245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, whisper_model, labels_unique, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    if FTRun:\n",
    "        whisper_model.train()\n",
    "    model.train() \n",
    "\n",
    "    train_loss = 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    total_pred = []\n",
    "    total_label = []\n",
    "\n",
    "    probability_0 = 0.5  # Probability for 0\n",
    "    probability_1 = 0.5  # Probability for 1\n",
    "\n",
    "    \n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        mels, labels, _ = batch\n",
    "\n",
    "        if augmentedRun:\n",
    "            for j in range(len(mels)):\n",
    "                # Generate random numbers based on the specified probabilities\n",
    "                random_numbers = random.choices([0, 1], weights=[probability_0, probability_1], k=1)\n",
    "\n",
    "                if(random_numbers[0] == 1):\n",
    "                    mels[j] = freq_masking(mels[j])\n",
    "                    mels[j] = time_masking(mels[j])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mels = mels.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        features = whisper_model.encoder(mels)\n",
    "\n",
    "        features = features.unsqueeze(1)\n",
    "\n",
    "        pred = model(features)\n",
    "\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred = pred.argmax(1)\n",
    "\n",
    "        pred = pred.cpu().detach()\n",
    "        pred = pred.numpy()\n",
    "        pred = pred.tolist()\n",
    "\n",
    "        labels = labels.cpu().detach()\n",
    "        labels = labels.numpy()\n",
    "        labels = labels.tolist()\n",
    "\n",
    "        total_pred.extend(pred)\n",
    "        total_label.extend(labels)\n",
    "\n",
    "        # # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), (i + 1) * len(features)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    print('Train Loss = {}'.format(train_loss))\n",
    "\n",
    "    var_report = classification_report(total_label, total_pred, labels = labels_unique, zero_division = 0.0)\n",
    "\n",
    "    try:\n",
    "        var_f1_score = f1_score(total_label, total_pred, labels = labels_unique, average='macro')\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'cnn_model_state_dict': model.state_dict(),\n",
    "            'whisper_model_state_dict': whisper_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            'f1_score': var_f1_score,\n",
    "            'report' : var_report,\n",
    "            \n",
    "            # Add other information you want to save\n",
    "        }\n",
    "        epoch_checkpoint = f\"{train_checkpoint_path}/checkpoint_epoch_{epoch}.pth\"\n",
    "        torch.save(checkpoint, epoch_checkpoint)    \n",
    "\n",
    "        # save outut in text file\n",
    "        add_log(f\"Epoch: {epoch+1} \\nTrain Stats: \\nTrain Loss = {train_loss} \\n\")\n",
    "\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, whisper_model, labels_unique, epoch):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    whisper_model.eval()\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        total_pred = []\n",
    "        total_label = []\n",
    "\n",
    "        for batch in dataloader:\n",
    "            mels, labels, _ = batch\n",
    "            \n",
    "            mels = mels.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            features = whisper_model.encoder(mels)\n",
    "\n",
    "            features = features.unsqueeze(1)\n",
    "\n",
    "            pred = model(features)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            test_loss += loss_fn(pred, labels).item()\n",
    "            correct += (pred.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "            pred = pred.argmax(1)\n",
    "\n",
    "            # pred = pred.argmax(1)\n",
    "\n",
    "            pred = pred.cpu().detach()\n",
    "            pred = pred.numpy()\n",
    "            pred = pred.tolist()\n",
    "\n",
    "            labels = labels.cpu().detach()\n",
    "            labels = labels.numpy()\n",
    "            labels = labels.tolist()\n",
    "\n",
    "            total_pred.extend(pred)\n",
    "            total_label.extend(labels)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        var_f1_score = f1_score(total_label, total_pred, labels = labels_unique, average='macro')\n",
    "\n",
    "        var_report = classification_report(total_label, total_pred, labels = labels_unique, zero_division = 0.0)\n",
    "\n",
    "        checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'loss': test_loss,\n",
    "                'f1_score': var_f1_score,\n",
    "                'report' : var_report,\n",
    "            }\n",
    "        epoch_checkpoint = f\"{test_checkpoint_path}/checkpoint_epoch_{epoch}.pth\"\n",
    "        torch.save(checkpoint, epoch_checkpoint)\n",
    "        print(f\"Test Result: \\n F1 Score: {var_f1_score} \\n\")\n",
    "\n",
    "        # Save output\n",
    "        add_log(f\"Test Stats: \\nF1-Score: {var_f1_score} \\nAccuracy: {(100*correct):>0.1f}% \\nAvg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    except:\n",
    "        print(\"Also Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1950b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a2e08",
   "metadata": {},
   "source": [
    "## CNN for Epoch-based Training and Testing\n",
    "\n",
    "The training and testing loops are executed over a specified number of epochs, utilizing CrossEntropyLoss and SGD optimizer. The script measures and displays the time taken for each epoch during training and testing phases, providing insights into the computational efficiency of the model. This setup is particularly useful for evaluating the performance of the combined CNN and Whisper model across multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf9b07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.392089  [   16/22998]\n",
      "loss: 5.088778  [ 1616/22998]\n",
      "loss: 5.209852  [ 3216/22998]\n",
      "loss: 5.144040  [ 4816/22998]\n",
      "loss: 5.309459  [ 6416/22998]\n",
      "loss: 5.297210  [ 8016/22998]\n",
      "loss: 5.284184  [ 9616/22998]\n",
      "loss: 5.102074  [11216/22998]\n",
      "loss: 4.444414  [12816/22998]\n",
      "loss: 4.784318  [14416/22998]\n",
      "loss: 4.731990  [16016/22998]\n",
      "loss: 4.964982  [17616/22998]\n",
      "loss: 4.427215  [19216/22998]\n",
      "loss: 3.924955  [20816/22998]\n",
      "loss: 4.223155  [22416/22998]\n",
      "Train Loss = 5.0258819940856165\n",
      "Epoch: 1 - Train Time: 382.3427357673645 seconds.\n",
      "Test Error: \n",
      " Accuracy: 4.7%, Avg loss: 4.563902 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.0067939517695405115 \n",
      "\n",
      "Epoch: 1 - Test Time: 61.96529722213745 seconds.\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.483295  [   16/22998]\n",
      "loss: 4.512063  [ 1616/22998]\n",
      "loss: 4.398746  [ 3216/22998]\n",
      "loss: 4.464755  [ 4816/22998]\n",
      "loss: 4.017120  [ 6416/22998]\n",
      "loss: 3.665313  [ 8016/22998]\n",
      "loss: 4.022079  [ 9616/22998]\n",
      "loss: 3.631437  [11216/22998]\n",
      "loss: 4.258847  [12816/22998]\n",
      "loss: 4.104192  [14416/22998]\n",
      "loss: 3.735105  [16016/22998]\n",
      "loss: 3.189624  [17616/22998]\n",
      "loss: 3.169858  [19216/22998]\n",
      "loss: 3.640459  [20816/22998]\n",
      "loss: 2.872102  [22416/22998]\n",
      "Train Loss = 3.9398780955061294\n",
      "Epoch: 2 - Train Time: 361.8496778011322 seconds.\n",
      "Test Error: \n",
      " Accuracy: 23.3%, Avg loss: 3.357846 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.10223484682308921 \n",
      "\n",
      "Epoch: 2 - Test Time: 74.48337078094482 seconds.\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.633737  [   16/22998]\n",
      "loss: 4.006593  [ 1616/22998]\n",
      "loss: 3.876838  [ 3216/22998]\n",
      "loss: 2.580882  [ 4816/22998]\n",
      "loss: 2.853131  [ 6416/22998]\n",
      "loss: 3.083478  [ 8016/22998]\n",
      "loss: 2.640270  [ 9616/22998]\n",
      "loss: 2.411124  [11216/22998]\n",
      "loss: 2.514810  [12816/22998]\n",
      "loss: 3.459571  [14416/22998]\n",
      "loss: 3.266149  [16016/22998]\n",
      "loss: 3.479412  [17616/22998]\n",
      "loss: 2.601830  [19216/22998]\n",
      "loss: 3.722746  [20816/22998]\n",
      "loss: 3.076022  [22416/22998]\n",
      "Train Loss = 3.1161468025706243\n",
      "Epoch: 3 - Train Time: 347.87129068374634 seconds.\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 2.720901 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.21685794361786453 \n",
      "\n",
      "Epoch: 3 - Test Time: 62.5742609500885 seconds.\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.138225  [   16/22998]\n",
      "loss: 3.385182  [ 1616/22998]\n",
      "loss: 3.197699  [ 3216/22998]\n",
      "loss: 2.715973  [ 4816/22998]\n",
      "loss: 2.368104  [ 6416/22998]\n",
      "loss: 2.137636  [ 8016/22998]\n",
      "loss: 3.460926  [ 9616/22998]\n",
      "loss: 2.663918  [11216/22998]\n",
      "loss: 1.962722  [12816/22998]\n",
      "loss: 3.269035  [14416/22998]\n",
      "loss: 2.400293  [16016/22998]\n",
      "loss: 1.177149  [17616/22998]\n",
      "loss: 2.703098  [19216/22998]\n",
      "loss: 2.042460  [20816/22998]\n",
      "loss: 2.070084  [22416/22998]\n",
      "Train Loss = 2.5585949932832546\n",
      "Epoch: 4 - Train Time: 358.48251080513 seconds.\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 3.151130 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.2607593016934927 \n",
      "\n",
      "Epoch: 4 - Test Time: 55.292723417282104 seconds.\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.532512  [   16/22998]\n",
      "loss: 1.787301  [ 1616/22998]\n",
      "loss: 2.242513  [ 3216/22998]\n",
      "loss: 1.820538  [ 4816/22998]\n",
      "loss: 1.853157  [ 6416/22998]\n",
      "loss: 1.694999  [ 8016/22998]\n",
      "loss: 2.250521  [ 9616/22998]\n",
      "loss: 1.969342  [11216/22998]\n",
      "loss: 2.330106  [12816/22998]\n",
      "loss: 2.513016  [14416/22998]\n",
      "loss: 2.138107  [16016/22998]\n",
      "loss: 2.301922  [17616/22998]\n",
      "loss: 1.804175  [19216/22998]\n",
      "loss: 2.050464  [20816/22998]\n",
      "loss: 1.892170  [22416/22998]\n",
      "Train Loss = 2.110573130249148\n",
      "Epoch: 5 - Train Time: 350.70769810676575 seconds.\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 2.279444 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.3750640771011823 \n",
      "\n",
      "Epoch: 5 - Test Time: 89.8538863658905 seconds.\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.681635  [   16/22998]\n",
      "loss: 1.644133  [ 1616/22998]\n",
      "loss: 2.325894  [ 3216/22998]\n",
      "loss: 1.697091  [ 4816/22998]\n",
      "loss: 1.093886  [ 6416/22998]\n",
      "loss: 2.355312  [ 8016/22998]\n",
      "loss: 3.427784  [ 9616/22998]\n",
      "loss: 1.173076  [11216/22998]\n",
      "loss: 1.337765  [12816/22998]\n",
      "loss: 1.167414  [14416/22998]\n",
      "loss: 2.481323  [16016/22998]\n",
      "loss: 1.391014  [17616/22998]\n",
      "loss: 1.322644  [19216/22998]\n",
      "loss: 0.976039  [20816/22998]\n",
      "loss: 0.916182  [22416/22998]\n",
      "Train Loss = 1.7485528008828408\n",
      "Epoch: 6 - Train Time: 365.95759677886963 seconds.\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 2.740157 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.4158641355493888 \n",
      "\n",
      "Epoch: 6 - Test Time: 60.48701524734497 seconds.\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.213608  [   16/22998]\n",
      "loss: 1.994880  [ 1616/22998]\n",
      "loss: 1.907591  [ 3216/22998]\n",
      "loss: 1.186633  [ 4816/22998]\n",
      "loss: 2.552256  [ 6416/22998]\n",
      "loss: 2.016771  [ 8016/22998]\n",
      "loss: 1.160318  [ 9616/22998]\n",
      "loss: 2.420914  [11216/22998]\n",
      "loss: 0.932690  [12816/22998]\n",
      "loss: 0.864144  [14416/22998]\n",
      "loss: 0.923826  [16016/22998]\n",
      "loss: 1.080868  [17616/22998]\n",
      "loss: 1.410012  [19216/22998]\n",
      "loss: 0.354896  [20816/22998]\n",
      "loss: 1.504461  [22416/22998]\n",
      "Train Loss = 1.4531185183886526\n",
      "Epoch: 7 - Train Time: 392.1376495361328 seconds.\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.434332 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.6032173404000291 \n",
      "\n",
      "Epoch: 7 - Test Time: 69.70066833496094 seconds.\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.437092  [   16/22998]\n",
      "loss: 0.995840  [ 1616/22998]\n",
      "loss: 1.412016  [ 3216/22998]\n",
      "loss: 1.241633  [ 4816/22998]\n",
      "loss: 2.070552  [ 6416/22998]\n",
      "loss: 0.961806  [ 8016/22998]\n",
      "loss: 1.583620  [ 9616/22998]\n",
      "loss: 0.651202  [11216/22998]\n",
      "loss: 1.081313  [12816/22998]\n",
      "loss: 1.477205  [14416/22998]\n",
      "loss: 1.343156  [16016/22998]\n",
      "loss: 1.001644  [17616/22998]\n",
      "loss: 0.962815  [19216/22998]\n",
      "loss: 1.131632  [20816/22998]\n",
      "loss: 0.391580  [22416/22998]\n",
      "Train Loss = 1.2035252942557295\n",
      "Epoch: 8 - Train Time: 366.53952503204346 seconds.\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 1.882630 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.537819122202232 \n",
      "\n",
      "Epoch: 8 - Test Time: 73.11083126068115 seconds.\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.314429  [   16/22998]\n",
      "loss: 1.320301  [ 1616/22998]\n",
      "loss: 1.779274  [ 3216/22998]\n",
      "loss: 1.495112  [ 4816/22998]\n",
      "loss: 1.515202  [ 6416/22998]\n",
      "loss: 0.385526  [ 8016/22998]\n",
      "loss: 0.943154  [ 9616/22998]\n",
      "loss: 0.484371  [11216/22998]\n",
      "loss: 0.997642  [12816/22998]\n",
      "loss: 1.928424  [14416/22998]\n",
      "loss: 1.623413  [16016/22998]\n",
      "loss: 0.577716  [17616/22998]\n",
      "loss: 0.672218  [19216/22998]\n",
      "loss: 0.300334  [20816/22998]\n",
      "loss: 1.838942  [22416/22998]\n",
      "Train Loss = 0.9739564454988661\n",
      "Epoch: 9 - Train Time: 347.73804545402527 seconds.\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 1.119051 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.7137118895280986 \n",
      "\n",
      "Epoch: 9 - Test Time: 62.53062963485718 seconds.\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.288102  [   16/22998]\n",
      "loss: 0.781363  [ 1616/22998]\n",
      "loss: 0.781968  [ 3216/22998]\n",
      "loss: 0.298437  [ 4816/22998]\n",
      "loss: 0.489147  [ 6416/22998]\n",
      "loss: 0.593130  [ 8016/22998]\n",
      "loss: 0.518299  [ 9616/22998]\n",
      "loss: 1.048766  [11216/22998]\n",
      "loss: 1.465224  [12816/22998]\n",
      "loss: 0.853423  [14416/22998]\n",
      "loss: 1.230838  [16016/22998]\n",
      "loss: 0.312042  [17616/22998]\n",
      "loss: 1.221860  [19216/22998]\n",
      "loss: 0.915039  [20816/22998]\n",
      "loss: 1.385634  [22416/22998]\n",
      "Train Loss = 0.8012343913508432\n",
      "Epoch: 10 - Train Time: 350.5615565776825 seconds.\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 1.169066 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.7114676740381889 \n",
      "\n",
      "Epoch: 10 - Test Time: 66.50108456611633 seconds.\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.523626  [   16/22998]\n",
      "loss: 0.685194  [ 1616/22998]\n",
      "loss: 0.195776  [ 3216/22998]\n",
      "loss: 0.146327  [ 4816/22998]\n",
      "loss: 0.918126  [ 6416/22998]\n",
      "loss: 1.203294  [ 8016/22998]\n",
      "loss: 0.370256  [ 9616/22998]\n",
      "loss: 0.696239  [11216/22998]\n",
      "loss: 0.476546  [12816/22998]\n",
      "loss: 1.371633  [14416/22998]\n",
      "loss: 0.532693  [16016/22998]\n",
      "loss: 0.425262  [17616/22998]\n",
      "loss: 0.248336  [19216/22998]\n",
      "loss: 0.506944  [20816/22998]\n",
      "loss: 0.178756  [22416/22998]\n",
      "Train Loss = 0.6217170850385463\n",
      "Epoch: 11 - Train Time: 369.4757959842682 seconds.\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 1.195976 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.7352532706921808 \n",
      "\n",
      "Epoch: 11 - Test Time: 58.70410418510437 seconds.\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.190532  [   16/22998]\n",
      "loss: 0.633806  [ 1616/22998]\n",
      "loss: 0.214170  [ 3216/22998]\n",
      "loss: 0.308594  [ 4816/22998]\n",
      "loss: 0.393670  [ 6416/22998]\n",
      "loss: 0.066152  [ 8016/22998]\n",
      "loss: 0.096494  [ 9616/22998]\n",
      "loss: 0.311597  [11216/22998]\n",
      "loss: 0.451854  [12816/22998]\n",
      "loss: 1.051923  [14416/22998]\n",
      "loss: 0.576498  [16016/22998]\n",
      "loss: 0.397760  [17616/22998]\n",
      "loss: 0.481526  [19216/22998]\n",
      "loss: 0.361074  [20816/22998]\n",
      "loss: 0.326607  [22416/22998]\n",
      "Train Loss = 0.5100669181853551\n",
      "Epoch: 12 - Train Time: 344.63207483291626 seconds.\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 1.121147 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.7686377473760614 \n",
      "\n",
      "Epoch: 12 - Test Time: 58.973188400268555 seconds.\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.039366  [   16/22998]\n",
      "loss: 0.415925  [ 1616/22998]\n",
      "loss: 0.498473  [ 3216/22998]\n",
      "loss: 0.148705  [ 4816/22998]\n",
      "loss: 0.092357  [ 6416/22998]\n",
      "loss: 0.702837  [ 8016/22998]\n",
      "loss: 0.087512  [ 9616/22998]\n",
      "loss: 0.142250  [11216/22998]\n",
      "loss: 0.065549  [12816/22998]\n",
      "loss: 0.230901  [14416/22998]\n",
      "loss: 0.251051  [16016/22998]\n",
      "loss: 0.060381  [17616/22998]\n",
      "loss: 0.020147  [19216/22998]\n",
      "loss: 0.305661  [20816/22998]\n",
      "loss: 0.607612  [22416/22998]\n",
      "Train Loss = 0.41502874887731994\n",
      "Epoch: 13 - Train Time: 352.9687113761902 seconds.\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.984396 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.801217986361065 \n",
      "\n",
      "Epoch: 13 - Test Time: 60.71695947647095 seconds.\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.008632  [   16/22998]\n",
      "loss: 0.613007  [ 1616/22998]\n",
      "loss: 0.324264  [ 3216/22998]\n",
      "loss: 0.415502  [ 4816/22998]\n",
      "loss: 0.396964  [ 6416/22998]\n",
      "loss: 0.189962  [ 8016/22998]\n",
      "loss: 0.085966  [ 9616/22998]\n",
      "loss: 0.402714  [11216/22998]\n",
      "loss: 0.022495  [12816/22998]\n",
      "loss: 0.599883  [14416/22998]\n",
      "loss: 0.517057  [16016/22998]\n",
      "loss: 0.293928  [17616/22998]\n",
      "loss: 0.017437  [19216/22998]\n",
      "loss: 0.646523  [20816/22998]\n",
      "loss: 0.179422  [22416/22998]\n",
      "Train Loss = 0.3486218895194521\n",
      "Epoch: 14 - Train Time: 348.8728654384613 seconds.\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 1.763794 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.6838079617542205 \n",
      "\n",
      "Epoch: 14 - Test Time: 62.357301235198975 seconds.\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.792945  [   16/22998]\n",
      "loss: 0.301606  [ 1616/22998]\n",
      "loss: 0.052325  [ 3216/22998]\n",
      "loss: 0.212567  [ 4816/22998]\n",
      "loss: 0.415336  [ 6416/22998]\n",
      "loss: 0.216129  [ 8016/22998]\n",
      "loss: 0.042868  [ 9616/22998]\n",
      "loss: 0.223741  [11216/22998]\n",
      "loss: 0.340205  [12816/22998]\n",
      "loss: 0.614656  [14416/22998]\n",
      "loss: 0.065304  [16016/22998]\n",
      "loss: 0.023856  [17616/22998]\n",
      "loss: 0.278863  [19216/22998]\n",
      "loss: 0.277943  [20816/22998]\n",
      "loss: 0.222852  [22416/22998]\n",
      "Train Loss = 0.29620546521538005\n",
      "Epoch: 15 - Train Time: 362.1229705810547 seconds.\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.977894 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.8075143330713913 \n",
      "\n",
      "Epoch: 15 - Test Time: 84.3525493144989 seconds.\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.117953  [   16/22998]\n",
      "loss: 0.014400  [ 1616/22998]\n",
      "loss: 0.069745  [ 3216/22998]\n",
      "loss: 0.121856  [ 4816/22998]\n",
      "loss: 0.305396  [ 6416/22998]\n",
      "loss: 0.039899  [ 8016/22998]\n",
      "loss: 0.064300  [ 9616/22998]\n",
      "loss: 0.675509  [11216/22998]\n",
      "loss: 0.717916  [12816/22998]\n",
      "loss: 0.014507  [14416/22998]\n",
      "loss: 0.031045  [16016/22998]\n",
      "loss: 0.389728  [17616/22998]\n",
      "loss: 0.079338  [19216/22998]\n",
      "loss: 0.271299  [20816/22998]\n",
      "loss: 0.418925  [22416/22998]\n",
      "Train Loss = 0.2503021018282816\n",
      "Epoch: 16 - Train Time: 364.80290365219116 seconds.\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 1.051623 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.8148896263224821 \n",
      "\n",
      "Epoch: 16 - Test Time: 82.15939664840698 seconds.\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.295943  [   16/22998]\n",
      "loss: 0.349326  [ 1616/22998]\n",
      "loss: 0.216643  [ 3216/22998]\n",
      "loss: 0.006915  [ 4816/22998]\n",
      "loss: 0.048849  [ 6416/22998]\n",
      "loss: 0.056857  [ 8016/22998]\n",
      "loss: 0.137247  [ 9616/22998]\n",
      "loss: 0.213711  [11216/22998]\n",
      "loss: 0.098942  [12816/22998]\n",
      "loss: 0.153644  [14416/22998]\n",
      "loss: 0.017491  [16016/22998]\n",
      "loss: 0.110051  [17616/22998]\n",
      "loss: 0.682773  [19216/22998]\n",
      "loss: 0.143502  [20816/22998]\n",
      "loss: 0.502810  [22416/22998]\n",
      "Train Loss = 0.205006835114543\n",
      "Epoch: 17 - Train Time: 358.4148952960968 seconds.\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.934899 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.8179510138763555 \n",
      "\n",
      "Epoch: 17 - Test Time: 57.994771242141724 seconds.\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.003736  [   16/22998]\n",
      "loss: 0.229082  [ 1616/22998]\n",
      "loss: 0.417429  [ 3216/22998]\n",
      "loss: 0.071384  [ 4816/22998]\n",
      "loss: 0.008385  [ 6416/22998]\n",
      "loss: 0.711486  [ 8016/22998]\n",
      "loss: 0.011188  [ 9616/22998]\n",
      "loss: 0.055359  [11216/22998]\n",
      "loss: 0.136322  [12816/22998]\n",
      "loss: 0.412894  [14416/22998]\n",
      "loss: 0.157150  [16016/22998]\n",
      "loss: 0.057531  [17616/22998]\n",
      "loss: 0.129176  [19216/22998]\n",
      "loss: 0.435564  [20816/22998]\n",
      "loss: 0.032190  [22416/22998]\n",
      "Train Loss = 0.19461056383692005\n",
      "Epoch: 18 - Train Time: 376.3739182949066 seconds.\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.962169 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.8153481852548373 \n",
      "\n",
      "Epoch: 18 - Test Time: 69.6755919456482 seconds.\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.020199  [   16/22998]\n",
      "loss: 0.177090  [ 1616/22998]\n",
      "loss: 0.716296  [ 3216/22998]\n",
      "loss: 0.234449  [ 4816/22998]\n",
      "loss: 0.077919  [ 6416/22998]\n",
      "loss: 0.139039  [ 8016/22998]\n",
      "loss: 0.070468  [ 9616/22998]\n",
      "loss: 0.447879  [11216/22998]\n",
      "loss: 0.004026  [12816/22998]\n",
      "loss: 0.116032  [14416/22998]\n",
      "loss: 0.451404  [16016/22998]\n",
      "loss: 0.018222  [17616/22998]\n",
      "loss: 0.279406  [19216/22998]\n",
      "loss: 0.002999  [20816/22998]\n",
      "loss: 0.112821  [22416/22998]\n",
      "Train Loss = 0.17745918881708156\n",
      "Epoch: 19 - Train Time: 375.30547976493835 seconds.\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 1.033115 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.8048819100121772 \n",
      "\n",
      "Epoch: 19 - Test Time: 56.42264699935913 seconds.\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.004257  [   16/22998]\n",
      "loss: 0.067121  [ 1616/22998]\n",
      "loss: 0.086414  [ 3216/22998]\n",
      "loss: 0.079887  [ 4816/22998]\n",
      "loss: 0.012372  [ 6416/22998]\n",
      "loss: 0.199995  [ 8016/22998]\n",
      "loss: 0.314910  [ 9616/22998]\n",
      "loss: 0.088174  [11216/22998]\n",
      "loss: 0.016934  [12816/22998]\n",
      "loss: 0.052888  [14416/22998]\n",
      "loss: 0.046695  [16016/22998]\n",
      "loss: 0.355607  [17616/22998]\n",
      "loss: 0.038722  [19216/22998]\n",
      "loss: 0.344692  [20816/22998]\n",
      "loss: 0.042711  [22416/22998]\n",
      "Train Loss = 0.15913807970121757\n",
      "Epoch: 20 - Train Time: 377.3041112422943 seconds.\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.997506 \n",
      "\n",
      "Test Result: \n",
      " F1 Score: 0.8221546116635926 \n",
      "\n",
      "Epoch: 20 - Test Time: 71.40619802474976 seconds.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "### Loading Model Start\n",
    "\n",
    "nn_model = CNN()\n",
    "nn_model = nn_model.to(device=device)\n",
    "\n",
    "# model = whisper.load_model(\"base\")\n",
    "model = whisper.load_model(\"base\")\n",
    "model = model.to(device=device)\n",
    "### Loading Model End\n",
    "\n",
    "# Apply the reinitialization to the model\n",
    "if randomWeight:\n",
    "    model.apply(reinitialize_weights)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "if FTRun: \n",
    "    params = list(model.encoder.parameters()) + list(nn_model.parameters())\n",
    "else:\n",
    "    params = nn_model.parameters()\n",
    "# print(params)\n",
    "\n",
    "optimizer = torch.optim.SGD(params, lr = 0.01)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for t in range(epochs):\n",
    "    train_start = time.time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, nn_model, loss_fn, optimizer, model, labels_unique, t)\n",
    "    train_end = time.time()\n",
    "    print(f\"Epoch: {t+1} - Train Time: {train_end - train_start} seconds.\")\n",
    "    add_log(f\"Train Time: {train_end - train_start} seconds. \\n\")\n",
    "\n",
    "    test_loop(test_dataloader, nn_model, loss_fn, model, labels_unique, t)\n",
    "    test_end = time.time()\n",
    "    print(f\"Epoch: {t+1} - Test Time: {test_end - train_end} seconds.\")\n",
    "    add_log(f\"Test Time: {test_end - train_end} seconds. \\n \\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
